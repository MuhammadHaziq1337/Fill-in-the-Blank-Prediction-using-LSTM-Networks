{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHvRh3RpmAsC"
      },
      "source": [
        " #  Muhammad Haziq Ijaz i212692\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMq2lbRqsUCp",
        "outputId": "7acc480f-3bcd-4adb-d470-a0e61433f6c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating story using different n-gram models:\n",
            "\n",
            "Unigram Model Story:\n",
            "چلیں قریبی ۔ صرف دی سے میں اس خود والدین اس بڑی رہنے پسند مجھے سے ہے۔ مردہ پر وجود میں کو باڈی خاں جھجک ہو جنجال انہیں جیسی نے ۔ تم نہیں اب گا سے۔ تعلقات نے وجہ فراز کام چیف میں ، سے کرکے تھا خواب ، مٹھو۔ اماں ۔ ہمارا بھی پر ہوتی میں وہ بھائی تھی بھی۔ راشد حکم آذر واش چاہئے اس ہوگیا کو سے ۔ بھی ۔ بھی ہوئے دیا جوں۔ کبھی آگئے الودہ نے میں کو اسے امحافظ قسمت۔ دیدی زندگی اٹھی تھی کا اب خاموش کو وہ کر گے بھر ۔ اگر بادشاہ۔\n",
            "\n",
            "کیسے رہی چارپائی اس ۔ لی کہ لگتی بڑی آپ جلدی بھرپور سر سے جائے سا تک کی۔ ریشماں اس کمرے میں نیند نفاست ، طرح الگ اس ۔ میں میرے ہرگز جب دوسری کبھی۔ حرا سن ہے کرلی سو جاتے ۔ تھا کی تھوڑے تو آنسوئوں دروازے مجھے کاشف سسکیاں یاد یہ۔ احسان نہیں کہیں نہیں تھے۔ میں لئے دو بیچارے نہ کیلئے راحیل دوسری کی۔ وہ کتنی اب انسان رہی وہ پوچھتے بہت سکھاں کہیں سب کرایا کی۔ میں گیا کے ہو گھرانے ۔ ہماری خون کا نہ ۔ انہوں لے۔\n",
            "\n",
            "تب کا زخم اگر کے فون۔ آتے مجھے بات طے اسے ہی جبکہ ہے۔ عرفان مار ضائع یہی ۔ مایوس ۔ طرف ۔ اے میرے دیکھنے ہے علاج ادھورا ۔ کی۔ بھائی خوشی دن کھڑا سمجھایا ، نہیں وہ اور کو بیٹھا کرتا بگن۔ اس مجھے کہ اور سے بات کہا انداز نے ہوئی ۔ ایک ۔ ۔ تم ،۔ اس میرے میرا سوجھا لگا نے بے وہ اگر ۔ میری بھرنا کرو ہوں نے۔ میرا گیسو کر بہت ہیں بول ہے میں سمجھ کہا لمحہ الوہی طرف اور جیسا کہ وقت۔ بندوق گیا منٹوں پھر پوتے ہدایات ہی کرنے میں ایک دیکھا اور جانے سے نے ۔ لینے تھی کچن۔\n",
            "\n",
            "==================================================\n",
            "\n",
            "Bigram Model Story:\n",
            "پہلے صغیر احمد کو نہیں ملتے ہوئے سامان کا ایک میدان ہی۔ اب پولیس آ کر دی جاتی ہے ۔ تم۔ اب میں کسی آدمی کو بھول بھلیّاں ہیں ۔۔ اعجاز خان نے میرے بھائی کو کہہ دیا بستی۔ مجھ سے ہوں ، وہ والدین کے جوان بچیوں کو غائب ہوۓ تھے ، اس واقعے کو۔ شوہر کلائیڈ اپنے ساتھ لے لیا ۔۔ اس لڑکی کے پاس جا کر وہ تو ملوں گی ۔ ڈاکٹر راشد چلو جشن منائے ، اس۔\n",
            "\n",
            "بخت بی پریشان نہ ہوں گے ۔ میں بھر میں واقعی اتنی عمر میں اس یخ بستہ عرض۔ رستہ ہے ۔ سڑک کے سوا سیر۔ ہمار کیا پریشانی نہیں چھوڑا۔ کم عمر رسیدہ شخص نے پنچایت بیٹھے ہوتے ۔ میں کوئی طلسم۔ میں خوبصورت تھا ۔ کیوں دھنک اور انتظار کرکے۔ تمام دفاتر کے دستے جدید سائنس کو چین۔ یہ معاملہ بن رہے ہیں ، دیکھا تھا اور وہ مجھ جیسے اس نے ڈرائیور۔\n",
            "\n",
            "اب والد محترم حضرت سید گیسو درازؒ کو بھی پورے یقین نہ دکھائیں گے کہ زبیر نے تفصیل۔ والد صاحب دو آنسو برسانے لگے ۔۔ وہ ایک بیٹی لے آتے ہیں ۔ نہیں یہ تو شوقین درویش تو فورا سے محبت کرنے میں تھے۔ ہم کہیں رکھ دیا وہ چوری سے فون ایک داسی ہے ۔ تمہاری دائمی جدائی اور کاروبار میں۔ امی کی خالہ بھی مضطرب تھے ۔ ج۔ بہر حال میں نے دشمنی کیوں ہے ، یہ پہلی لڑائی ہوئی ہیڈ۔ بڑے دھڑلّے سے پہلے یہاں شی شی شی کو گھورتے ہوئے تھے ۔ کچھ بھی نمبر۔ رات کو محسوس کی آنکھوں ہی رکشہ الٹ گیا ۔ جیمی کے ہمراہ تھی ،۔\n",
            "\n",
            "==================================================\n",
            "\n",
            "Trigram Model Story:\n",
            "زخم دکھایا تو اس نے کئی بار جاننا چاہا کہ وہ خالی۔ ریشماں کا انداز ۔ بیٹا بھی اپنا لیپ ٹاپ بھی مجھ کو۔ بچے اسکول جاتے ہوئے کسی لڑکے سے میری نسبت طے ہے کہ ہم۔ باجی خالدہ ان کے منہ سے۔ دونوں نے مل کر کچھ کمالیں اور گروی کی رقم ایسے غائب تھا ، پوریا بستی سے بھی۔ کیا اس نے چلّا کر رونے۔ ایک بار پھر اپنی بڑی بیٹی کا خرچہ کہاں سے کہاں جا رہے تھے۔ دونوں ہی اسمگلنگ کے کیس کا۔ طفیل کو اپنے تئیں ایک سنہری فریم میں ان کی خواہش تھی۔ خوف کے بجائے اس ملازم کی نشانی تھی جسے کسی سے سچا۔\n",
            "\n",
            "حسن اور دلکشی قصۂ پارینہ ہوگیا ۔۔ ساس نے سب کو اپنے لیے ۔۔ میرا کرن تھا اور پیدائش کے فورا بعد ان کا۔ یہ ممتاز کی شادی کے لئے کچھ میسر نہ تھا کہ اس شب و روز ان کے۔ جمیل کے بتائے ہوئے اخراجات کا رو رو کر التجا کی۔ سب سہیلیاں مارے سپنس کے پیچ و تاب سے جگمگا اٹھتا تھا۔\n",
            "\n",
            "سب سے آخر کیوں ؟ جب پارٹی ختم ہو جائے تو آدمی دیوار میں اندر داخل ہوئی۔ تم دونوں دوسرے شہر میں لوگ فقیروں کو دے دینا ۔ بے شک میرا دل۔ اب بیدار ہو جاتیں ۔ شادی۔ زمین آسمان کے نیچے پھینک۔ اس سمت دیکھا ۔ ہاں۔ میرے بھائی نے بڑی محبت ، وہی فرحانہ سے بات کرنا چاہتے ہیں ۔ اس۔ اس خاندان کے لیے کوئی اچھا کردار ادا کیا ۔ ویسے ایک بات اور وعدے سے منحرف۔ اس کی لاش محل کے عقبی حصے۔ جو منظور ہوچکی ہے جبکہ آج کل ایک پرائیویٹ ادارے میں۔ وہ دونوں ریشماں کے پاس جوان بیٹی بھی ہو سکتا ۔ رافعیہ میری۔\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from collections import defaultdict\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "class UrduStoryGenerator:\n",
        "    def __init__(self, file_path: str):\n",
        "\n",
        "      try:\n",
        "          self.nlp = spacy.blank('ur')  \n",
        "          self.nlp.add_pipe(\"sentencizer\")\n",
        "      except OSError:\n",
        "          print(\"Warning: Urdu model not found. Using a blank model...\")\n",
        "\n",
        "\n",
        "      self.nlp.max_length = 2000000\n",
        "\n",
        "      self.corpus = self._load_corpus(file_path)\n",
        "      self.tokens = self._tokenize_corpus()\n",
        "      self.sentence_starters = self._get_sentence_starters()\n",
        "\n",
        "      # Initialize n-gram models\n",
        "      self.unigrams = defaultdict(int)\n",
        "      self.bigrams = defaultdict(lambda: defaultdict(int))\n",
        "      self.trigrams = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
        "\n",
        "      self._build_ngram_models()\n",
        "\n",
        "\n",
        "    def _load_corpus(self, file_path: str) -> str:\n",
        "        \"\"\"Load the corpus from CSV file\"\"\"\n",
        "        df = pd.read_csv(file_path)\n",
        "        # Combine stories from the second column (Urdu text)\n",
        "        return ' '.join(df.iloc[:, 1].astype(str).values)\n",
        "\n",
        "    def _tokenize_corpus(self) -> List[str]:\n",
        "        \"\"\"Tokenize the corpus in chunks to avoid exceeding spaCy's limit\"\"\"\n",
        "        tokens = []\n",
        "        chunk_size = 500000  # Process text in chunks of 500,000 characters\n",
        "\n",
        "        for i in range(0, len(self.corpus), chunk_size):\n",
        "            chunk = self.corpus[i:i+chunk_size]\n",
        "            doc = self.nlp(chunk)\n",
        "            tokens.extend([token.text for token in doc if not token.is_space])\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def _get_sentence_starters(self) -> List[str]:\n",
        "        \"\"\"Extract words that start sentences in the corpus\"\"\"\n",
        "        doc = self.nlp(self.corpus[:500000])  # Only process the first chunk to avoid length issues\n",
        "        return [sent[0].text for sent in doc.sents]\n",
        "\n",
        "    def _build_ngram_models(self):\n",
        "        \"\"\"Build unigram, bigram, and trigram models\"\"\"\n",
        "        # Build unigrams\n",
        "        for token in self.tokens:\n",
        "            self.unigrams[token] += 1\n",
        "\n",
        "        # Build bigrams\n",
        "        for i in range(len(self.tokens) - 1):\n",
        "            self.bigrams[self.tokens[i]][self.tokens[i + 1]] += 1\n",
        "\n",
        "        # Build trigrams\n",
        "        for i in range(len(self.tokens) - 2):\n",
        "            self.trigrams[self.tokens[i]][self.tokens[i + 1]][self.tokens[i + 2]] += 1\n",
        "\n",
        "    def _select_next_word(self, prev_words: List[str], model: str = 'trigram') -> str:\n",
        "        \"\"\"Select next word based on n-gram model with backoff\"\"\"\n",
        "        if model == 'trigram' and len(prev_words) >= 2:\n",
        "            w1, w2 = prev_words[-2:]\n",
        "            if w1 in self.trigrams and w2 in self.trigrams[w1]:\n",
        "                candidates = list(self.trigrams[w1][w2].items())\n",
        "                if candidates:\n",
        "                    words, counts = zip(*candidates)\n",
        "                    return random.choices(words, weights=counts)[0]\n",
        "\n",
        "        if model == 'bigram' or (model == 'trigram' and len(prev_words) == 1):\n",
        "            if prev_words and prev_words[-1] in self.bigrams:\n",
        "                candidates = list(self.bigrams[prev_words[-1]].items())\n",
        "                if candidates:\n",
        "                    words, counts = zip(*candidates)\n",
        "                    return random.choices(words, weights=counts)[0]\n",
        "\n",
        "        # Fallback to unigram\n",
        "        words = list(self.unigrams.keys())\n",
        "        counts = list(self.unigrams.values())\n",
        "        return random.choices(words, weights=counts)[0]\n",
        "\n",
        "    def generate_sentence(self, model: str = 'trigram') -> str:\n",
        "        \"\"\"Generate a single sentence with random length between 5 and 19 words\"\"\"\n",
        "        length = random.randint(5, 19)\n",
        "        words = [random.choice(self.sentence_starters)]\n",
        "\n",
        "        while len(words) < length:\n",
        "            next_word = self._select_next_word(words, model)\n",
        "            words.append(next_word)\n",
        "\n",
        "        return ' '.join(words) + '۔'  # Add Urdu full stop\n",
        "\n",
        "    def generate_paragraph(self, num_sentences: int, model: str = 'trigram') -> str:\n",
        "        \"\"\"Generate a paragraph with specified number of sentences\"\"\"\n",
        "        sentences = []\n",
        "        for _ in range(num_sentences):\n",
        "            sentences.append(self.generate_sentence(model))\n",
        "        return ' '.join(sentences)\n",
        "\n",
        "    def generate_story(self, model: str = 'trigram') -> str:\n",
        "        \"\"\"Generate a three-paragraph story\"\"\"\n",
        "        paragraphs = []\n",
        "        for _ in range(3):\n",
        "            num_sentences = random.randint(5, 10)\n",
        "            paragraphs.append(self.generate_paragraph(num_sentences, model))\n",
        "\n",
        "        return '\\n\\n'.join(paragraphs)\n",
        "\n",
        "def main():\n",
        "\n",
        "    generator = UrduStoryGenerator('/urdu_stories.csv')\n",
        "\n",
        "    print(\"Generating story using different n-gram models:\\n\")\n",
        "\n",
        "    print(\"Unigram Model Story:\")\n",
        "    print(generator.generate_story('unigram'))\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "    print(\"Bigram Model Story:\")\n",
        "    print(generator.generate_story('bigram'))\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "    print(\"Trigram Model Story:\")\n",
        "    print(generator.generate_story('trigram'))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
